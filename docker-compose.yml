# Database and embedding services for codesearch
# The codesearch CLI runs natively and connects to these containerized services
#
# Usage:
#   Default (NVIDIA GPU auto-detect or CPU fallback):
#     docker compose up -d
#     - Automatically uses NVIDIA GPU if nvidia-container-runtime is available
#     - Falls back to CPU if no GPU (slower but works everywhere)
#
#   AMD ROCm GPU (requires AMD MI200/MI300/RX7900 + ROCm 6.2+):
#     docker compose --profile rocm up -d
#
#   Only Qdrant (no embeddings):
#     docker compose up qdrant
#
# Note: Only one vLLM service can run at a time (both use port 8000)

services:
  qdrant:
    image: qdrant/qdrant:latest-unprivileged
    container_name: codesearch-qdrant
    ports:
      - "127.0.0.1:6333:6333"  # REST API port - localhost only
      - "127.0.0.1:6334:6334"  # gRPC port - localhost only
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__LOG_LEVEL=INFO
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:6333/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped

  postgres:
    image: postgres:17
    container_name: codesearch-postgres
    ports:
      - "127.0.0.1:5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./migrations:/docker-entrypoint-initdb.d:ro
    environment:
      - POSTGRES_DB=codesearch
      - POSTGRES_USER=codesearch
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-codesearch}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U codesearch -d codesearch"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  outbox-processor:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: codesearch-outbox-processor
    depends_on:
      postgres:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DATABASE=codesearch
      - POSTGRES_USER=codesearch
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-codesearch}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6334
      - QDRANT_REST_PORT=6333
      - QDRANT_COLLECTION=codesearch
      - RUST_LOG=${RUST_LOG:-info}
    restart: unless-stopped

  vllm-embeddings:
    image: vllm/vllm-openai:latest
    container_name: codesearch-vllm
    ports:
      - "127.0.0.1:8000:8000"  # OpenAI-compatible API - localhost only
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ipc: host
    command:
      - "--model"
      - "BAAI/bge-code-v1"
      - "--task"
      - "embed"
      - "--gpu-memory-utilization"
      - "0.8"
      - "--dtype"
      - "float32"
      - "--max-model-len"
      - "32768"
      - "--max-num-batched-tokens"
      - "32768"
      - "--max-num-seqs"
      - "1024"
      - "--trust-remote-code"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s  # Allow time for model loading
    restart: unless-stopped

  vllm-embeddings-rocm:
    image: rocm/vllm:latest
    container_name: codesearch-vllm-rocm
    profiles:
      - rocm
    ports:
      - "127.0.0.1:8000:8000"  # OpenAI-compatible API - localhost only
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - video
    ipc: host
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    command:
      - "--model"
      - "BAAI/bge-code-v1"
      - "--task"
      - "embed"
      - "--gpu-memory-utilization"
      - "0.8"
      - "--dtype"
      - "float32"
      - "--max-model-len"
      - "32768"
      - "--max-num-batched-tokens"
      - "32768"
      - "--max-num-seqs"
      - "1024"
      - "--trust-remote-code"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s  # Allow time for model loading
    restart: unless-stopped

volumes:
  qdrant_data:
    driver: local
  postgres_data:
    driver: local